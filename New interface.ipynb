{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, linewidth=280)\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from typing import List, Dict\n",
    "from recstate import C_, mu_, Sigma_, dC_, dmu_, dSigma_, RG, new_state, G_matrix\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def grad_state(gamma, phi, zeta, psi):\n",
    "    \"\"\"\n",
    "    Gradient of the new state\n",
    "    \"\"\"\n",
    "    \n",
    "    C = C_(gamma, phi, zeta)\n",
    "    dC = dC_(gamma, phi, zeta)\n",
    "    mu = mu_(gamma, phi, zeta)\n",
    "    dmu = dmu_(gamma, phi, zeta)\n",
    "    Sigma = Sigma_(gamma, phi, zeta)\n",
    "    dSigma = dSigma_(gamma, phi, zeta)\n",
    "    \n",
    "    R, G = RG(C, mu, Sigma, psi)\n",
    "    \n",
    "    cutoff = len(psi)\n",
    "    dtype = psi.dtype\n",
    "    sqrt = np.sqrt(np.arange(cutoff, dtype=dtype))\n",
    "    order = None\n",
    "    if order is None:\n",
    "        order = cutoff\n",
    "    \n",
    "    dR = np.zeros((cutoff, cutoff, 5), dtype=dtype)\n",
    "    dG = np.zeros((cutoff, 5), dtype=dtype)\n",
    "    \n",
    "    # grad of first row of Transformation matrix\n",
    "    dG[0] = dC\n",
    "    for n in range(cutoff-1):\n",
    "        dG[n+1] = (dmu[1]*G[n] + mu[1]*dG[n] - dSigma[1,1]*sqrt[n]*G[n-1] - Sigma[1,1]*sqrt[n]*dG[n-1])/sqrt[n+1]\n",
    "    \n",
    "    # first row of dR matrix\n",
    "    for n in range(cutoff):\n",
    "        dR[0, n] = np.dot(np.transpose(dG[:cutoff - n]), psi)\n",
    "        psi = psi[1:]*sqrt[1:cutoff-n]\n",
    "\n",
    "    # rest of dR matrix\n",
    "    for m in range(cutoff - 1):\n",
    "        for k in range(cutoff - m - 1):\n",
    "            dR[m+1, k] = (dmu[0]*R[m, k] + mu[0]*dR[m, k] - dSigma[0,0]*sqrt[m]*R[m-1, k] - Sigma[0,0]*sqrt[m]*dR[m-1, k] - Sigma[0,1]*dR[m, k+1] - dSigma[0,1]*R[m, k+1])/sqrt[m+1]\n",
    "            \n",
    "    return np.transpose(dR[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def Ggate(gamma, phi, zeta, Psi):\n",
    "    \"\"\"\n",
    "    Direct evolution of a quantum state\n",
    "    \"\"\"\n",
    "    gamma = gamma.numpy()\n",
    "    phi = phi.numpy()\n",
    "    zeta = zeta.numpy()\n",
    "    Psi = Psi.numpy()\n",
    "    cutoff = Psi.shape[0]\n",
    "    \n",
    "    Psi_new = new_state(gamma, phi, zeta, Psi)\n",
    "    \n",
    "    def grad(dy):\n",
    "        \"Vector-Jacobian products for all the arguments (gamma, phi, zeta, Psi)\"\n",
    "        dPsi_dgamma, dPsi_dgammac, dPsi_dphi, dPsi_dz, dPsi_dzc = grad_state(gamma, phi, zeta, Psi) # gradients wrt g,g*,phi,z,z* \n",
    "        grad_gammac = tf.reduce_sum(dy*np.conj(dPsi_dgamma) + tf.math.conj(dy)*dPsi_dgammac)\n",
    "        grad_phi = tf.math.real(tf.reduce_sum(dy*np.conj(dPsi_dphi))) # was *2\n",
    "        grad_zetac = tf.reduce_sum(dy*np.conj(dPsi_dz) + tf.math.conj(dy)*dPsi_dzc)\n",
    "        grad_Psic = tf.linalg.matvec(G_matrix(gamma, phi, zeta, cutoff), dy, adjoint_a=True)\n",
    "        \n",
    "        return grad_gammac, grad_phi, grad_zetac, grad_Psic\n",
    "    \n",
    "    return Psi_new, grad\n",
    "\n",
    "def kerr(k, cutoff):\n",
    "    diag = tf.exp(1j*tf.cast(k, dtype=tf.complex128)*np.arange(cutoff)**2)\n",
    "    return diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_complex(layers, scale=0.01):\n",
    "    return np.random.normal(scale=scale, size=layers) + 1j*np.random.normal(scale=scale, size=layers)\n",
    "\n",
    "def init_real(layers, scale=0.01):\n",
    "    return np.random.normal(scale=scale, size=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Variables:\n",
    "    gamma: tf.Variable\n",
    "    phi: tf.Tensor\n",
    "    zeta: tf.Variable\n",
    "    kappa: tf.Variable\n",
    "    \n",
    "    @property\n",
    "    def learnable(self):\n",
    "        return [var for var in (self.gamma, self.phi, self.zeta, self.kappa) if isinstance(var, tf.Variable)]\n",
    "    \n",
    "    @property\n",
    "    def all(self):\n",
    "        return (self.gamma, self.phi, self.zeta, self.kappa)\n",
    "    \n",
    "    @property\n",
    "    def L1_norm(self):\n",
    "        tensor = tf.stack([tf.cast(var, tf.complex128) for var in self.all])\n",
    "        return tf.abs(tf.linalg.norm(tensor, ord=1))\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    state_in:np.array\n",
    "    objective:np.array\n",
    "    dtype: tf.dtypes.DType\n",
    "    num_layers: int\n",
    "    steps: int\n",
    "    optimizer: str = 'SGD'\n",
    "    LR: float = 0.001\n",
    "    LR_schedule: dict = field(default_factory=dict) # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circuit:\n",
    "    def __init__(self, config:Config):\n",
    "        self.config = config\n",
    "        \n",
    "        self.state_in = tf.cast(tf.constant(config.state_in), dtype=config.dtype)\n",
    "        self.objective = tf.cast(tf.constant(config.objective), dtype=config.dtype)\n",
    "        self._state_out = None\n",
    "        \n",
    "        self.cutoff = self.state_in.shape[0]\n",
    "        self.optimizer = tf.optimizers.__dict__[config.optimizer](config.LR)\n",
    "        \n",
    "        gamma = tf.Variable(init_complex(self.config.num_layers, 0.01), dtype=tf.complex128, name=f'gamma')\n",
    "        phi = tf.constant(init_real(self.config.num_layers), dtype=tf.float64, name=f'phi')\n",
    "        zeta = tf.Variable(init_complex(self.config.num_layers, 0.01), dtype=tf.complex128, name=f'zeta')\n",
    "        kappa = tf.Variable(init_real(self.config.num_layers, 0.01), dtype=tf.float64, name=f'kappa')\n",
    "        \n",
    "        self.variables = Variables(gamma, phi, zeta, kappa)\n",
    "        \n",
    "\n",
    "    def _layer_out(self, gamma: tf.Tensor, phi: tf.Tensor, zeta: tf.Tensor, k: tf.Tensor, layer_in: tf.Tensor) -> tf.Tensor:\n",
    "        layer_out = Ggate(gamma, phi, zeta, layer_in)\n",
    "        return kerr(k, self.cutoff)*layer_out\n",
    "    \n",
    "    @property # lazy property\n",
    "    def state_out(self) -> tf.Tensor:\n",
    "        if self._state_out is None: \n",
    "            state = self.state_in\n",
    "            for i in range(self.config.num_layers):\n",
    "                state = self._layer_out(self.variables.gamma[i], self.variables.phi[i], self.variables.zeta[i], self.variables.kappa[i], state)\n",
    "            self._state_out = state\n",
    "        return self._state_out\n",
    "    \n",
    "    @property\n",
    "    def fidelity(self) -> tf.float64:\n",
    "        return tf.abs(tf.reduce_sum(self.state_out*tf.math.conj(self.objective)))**2\n",
    "\n",
    "    def loss(self) -> tf.float64:\n",
    "        return 1.0 - self.fidelity\n",
    "\n",
    "    def minimize_step(self) -> float:\n",
    "        self._state_out = None # reset lazy output state\n",
    "        self.optimizer.minimize(self.loss, self.variables.learnable)\n",
    "        return self.loss()\n",
    "        \n",
    "\n",
    "    def minimize(self) -> list:\n",
    "        \n",
    "        loss_list = []\n",
    "        for i in tqdm(range(self.config.steps)):\n",
    "            try:\n",
    "                loss_list.append(self.minimize_step())\n",
    "\n",
    "                # LR scheduling\n",
    "                for threshold, new_LR in self.config.LR_schedule.items():\n",
    "                    if loss_list[-1] < threshold:\n",
    "                        self.optimizer.lr = new_LR\n",
    "\n",
    "                if i%10 == 0:\n",
    "                    print(f\"Fidelity = {100*(self.fidelity):.3f}%, LR = {self.optimizer.lr.numpy():.5f}\", end='\\r')\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"other exception: {e}\")\n",
    "                raise e\n",
    "        return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    state_in = np.identity(50)[0], # vacuum\n",
    "    objective = np.identity(50)[1], # 1 photon\n",
    "    dtype=tf.complex128,\n",
    "    num_layers=8, \n",
    "    steps=500,\n",
    "    optimizer='Adam', \n",
    "    LR=0.002, \n",
    "    LR_schedule={0.1:0.001, 0.05:0.001, 0.01:0.0005, 0.005:0.0001, 0.001:0.00005}\n",
    ")\n",
    "\n",
    "experiment = Circuit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba759f89e7b478e9d29646d18f2adf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 99.813%, LR = 0.00010\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_list = experiment.minimize()\n",
    "plt.plot(loss_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
